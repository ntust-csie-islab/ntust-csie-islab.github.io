<html><head><title>王文堂發表論文</title>
<link rev="made" href="mailto:m8302001@et.ntit.edu.tw">
</head>
<body background="/picture/gray_roc.gif">
<pre><h3>
 82級畢業碩士  王文堂  發表論文</h3></pre>

<hr>
<a name="paper1"><h4>An Architecture of Neural Network Classifier with Fuzzy Teaching Inputs</h4></a> 

<h4>Abstract</h4>
<blockquote>
A neural network for classification problems with fuzzy inputs is proposed. A fuzzy input is represented as a <i>LR</i>-type fuzzy set. A 
generalized pocket algorithm, called fuzzy pocket algorithm, that utilizes <i>LR</i>-type fuzzy sets operations and defuzzification method is 
proposed to train a linear threshold unit (LTU). This LTU node will classify as many fuzzy input instances as possible. Afterwards, FV 
nodes that represent fuzzy interval vectors will then be generated and expanded, by proposed FVGE learning algorithm, to classify those 
fuzzy input instances that cannot be classified by the LTU node. The similarity degree between FV nodes and fuzzy inputs is measured 
by the fuzzy subsethood degree. The FVGE learning algorithm can be applied to hyperbox-based classifiers, e.g., Fuzzy ART series, 
Fuzzy Min-Max Classifier. The network structure is automatically generated. Besides, on-line learning is supplied and learning speed is 
fast. Two sample problems, called heart disease and knowledge-based evaluator, are considered to illustrate the workings of the 
proposed model. The experimental results are very encouraging.
</blockquote>


<hr>
<a name="paper2"><h4>Training of a Neural Network Classifier by Combining Hyperplane with Exemplar Approach</h4></a>

<h4>Abstract</h4>
<blockquote>
A neural network classifier which combines hyperplane with exemplar approach is presented. The network structure does not have to be 
specified before training and an appropriate network structure will be build during training. Perceptron-based algorithm is first applied to
train a linear threshold unit(LTU). The LTU will build a hyperplane that classifies as many training instances as possible. Afterwards, HB
nodes that represent hyperboxes will be generated to classified by the hyperplane. The proposed model also works well on both 
clustered and strip-distributed instances. Number of HB nodes generated depends on the overlapping degree of training instances. This 
classify continuous-valued and nonlinearly separable instances. In addition, on-line learning is supplied and learning speed is very fast.
Furthermore, the parameters used are few and insensitive.
</blockquote>


<hr>
<a name="paper3"><h4>A Neural Network Architecture for Classification of Fuzzy Inputs</h4></a> 

<h4>Abstract</h4>
<blockquote>
A neural network for classification problems with fuzzy inputs is proposed. A fuzzy input is represented as a <i>LR</i>-type fuzzy set. A 
generalized pocket algorithm, called fuzzy pocket algorithm, that uses  <i>LR</i>-type fuzzy sets operations and defuzzification method is 
proposed to train a linear threshold unit (LTU). This LTU node will classify as many fuzzy input instances as possible. Afterwards, FV 
nodes that represent fuzzy vectors will then be generated and expanded, by proposed FVGE learning algorithm, to classify those fuzzy
input instances that cannot be classified by the LTU node. The similarity degree between FV nodes and fuzzy inputs is measured by the
fuzzy subsethood degree. The network structure is automatically generated. The number of hidden nodes generated depends on the 
overlapping degree of training instances. Besides, on-line learning is supplied, and parameters used are few and insensitive. The 
relationship between proposed model and hyperbox-based classifiers, e.g., Fuzzy ART series and Fuzzy Min-Max series, is also 
discussed. Two sample problems, heart disease and knowledge-based evaluator, are considered to illustrate the working of the 
proposed model. The experimental results are very encouraging.
</blockquote>

<h4>Keywords</h4>
<blockquote>
Fuzzy sets; membership function; <i>LR</i>-type fuzzy interval; pattern recognition; neural networks; Pocket algorithm
</blockquote>


<hr>
</html>  








