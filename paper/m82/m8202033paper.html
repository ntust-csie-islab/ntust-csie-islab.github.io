<html>
<head>
  <title>
         ¬ì§Þ¤j¾Ç¼Ò½kÃþ¯«¸gºô¸ô¹êÅç«Ç  ¬ã¨s½×¤å
         NTUST Fuzzy Neural Lab  Paper
  </title>
</head>
<img align=left src="/picture/logo.gif">
<strong><font size=4>
°ê¥ß¥xÆW¬ì§Þ¤j¾Ç  ¹q¤l¤uµ{¨t©Ò<BR>
<font size=6>
½kÃþ¯«¸gºô¸ô¹êÅç«Ç  ¬ã¨s½×¤å<BR>
<font size=4>
Fuzzy Neuron Laboratory Paper<BR>
</font></font></strong>
<body background="/picture/gray_roc.gif"
        bgcolor="#ffffff" text="#000000 link="#55ffff" vlink="#6966ff">
<hr size=10>
<h2>84¯Å²¦·~ºÓ¥Í  ®}¥òªNâ  µoªí½×¤å</h2>
<hr size=5>
<h3>A Multiclass Neural Network Classifier with Fuzzy Teaching Input</h3>
<h4>Abstract</h4>
<blockquote>
 This paper presents a multiclass neural network classifier with fuzzy teaching 
inputs.  The classifier creates each class by aggregating a fuzzy prototype
and several fuzzy exemplars in the hidden layer.  Fuzzy inputs and all the nodes in the
hidden layer are represented by trapezoidal fuzzy numbers.  We train the classifier by a
two-pass learning algorithm.  In pass one, a very fast one-epoched algorithm PECFUH 
(Prototype Expansion and Contraction of FUzzy Hyperbox) or FUNLVQ (FUzzy Number's Learning Vector Quantization) is used to train the prototypes. 
These prototypes will classify as many fuzzy input instances as possible. 
Afterward, exemplars that mean the exceptions, like the "holes," in pattern space will
be generated and expanded in pass two to classify those fuzzy input instances that cannot
be correctly classified by the prototypes.  We propose a few-epoched FENCE
(Fuzzy Exemplar Nested Creation and Expansion) training algorithm to create the
exemplar nodes.  Due to the training in pass one, the number of exemplar nodes is
reduced and the learning speed is very fast during pass two.  In addition, on-line
adaptation is supplied in this model and the computational load is lightened.  Also,
nonlinearly separable instances and overlapping classes can be handled well. 
Furthermore, this classifier has good generalization ability for the training instances with
don't-care information.  The experimental results manifest that the training and
recalling are fast.  At the same time, they illustrate that required nodes are few.
</blockquote>
</body>
</html>
