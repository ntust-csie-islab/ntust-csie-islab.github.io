95級

楊勝源 (Sheng-Yuan Yang) D8502501

新一代智慧型網路資訊系統FAQ-master

本論文闡述我們發展智慧型網路資訊系統FAQ-master的成果。FAQ-master具有從浩瀚網際中，有效發現、擷取、過濾、代取、排序與呈現高品質資訊，來滿足使用者資訊需求的能力。所謂高品質資訊的意義就是具深度、最新且貼近於使用者問題的解答。論文中探討下列問題：如何忠實且傳神地擷取使用者的意圖、如何有效地發現與整合鬆散無特定結構的網路資訊、如何呈現給使用者相關的查詢結果、以及如何提供有效的代取機制縮短系統的回應時間。提出的技術包括：本體論、使用者模式、網站模式、以及資料整合與代取機制。本論文並勾勒出FAQ-master的四個主要組件，亦即介面代理人、代取代理人、答覆代理人與搜尋代理人的系統架構，祈能從使用者意圖、網頁文件處理與網站搜尋等三個觀點，有效地改善網際網路搜尋的成果。
介面代理人扮演使用者與系統間的溝通者，來抓取使用者真正的查詢意圖。在使用者塑模、樣板及本體論支援下，本代理人提供增強式型樣與樣板比對之自然語言查詢、人機溝通之協助與引導、以及較佳的個人化資訊服務，亦能處理使用者針對提供解答的回饋。代取代理人則扮演介面代理人與後端答覆代理人間之兩階段中介者，引進本體論增強之智慧式代取機制，可有效降低後端伺服器資料庫的擷取負擔。答覆代理人負責清理、擷取與轉換來自不同網站的資訊，並存成本體論主導的資料庫。本代理人引進包裝器技術，將搜尋代理人收集的網頁資訊在系統後端進行本體論主導的資訊匯集。最後，搜尋代理人藉由本體論支援的網站模式，執行使用者導向與領域相關兼顧的網路資訊擷取。這種語意層次解答的做法，使得搜尋代理人能提供具使用者高滿意度之特定領域聚焦的網路資訊探索。
本系統的成果之一為發展介面代理人的本體論支援與樣板為主之使用者塑模及查詢處理的技術。我們初步的實驗結果顯示，近八成的使用者問句可由本系統正確地辨識出使用者的查詢意圖與焦點。此外，實驗也驗證了樣式匹配技術的完整性，對於了解使用者問句的意圖與焦點相當有效。
本系統的成果之二為發展代取代理人的查詢預測技術。本代理人的特色為(1)利用完美雜湊與資料庫分解之改良式的循序型樣採掘技術，自使用者查詢歷史紀錄中，挖掘出使用者查詢行為，進行使用者導向之快速採掘及預測；(2)利用PC本體論中的VRelationships，進行本體論主導之改良式案例式推理。實驗顯示，本系統大約可舒緩後端答覆代理人約70 %的工作負擔，很明顯的改善了整體的查詢效能。
本系統的成果之三為發展答覆代理人的組織與處理鬆散無特定結構之網路資訊技術。本代理人引進本體論支援的包裝器技術，對來自異質環境下的FAQ資訊進行清理、擷取與轉換，並儲存在一個依知識本體結構建構的整合式資料庫；利用本體論支援去除FAQ雜訊、不一致、或互衝的情形，採用全部關鍵詞包含式或部分關鍵詞包含式的方式，擷取出更多可供回覆的FAQ。為呈現最正確有效的解答，本代理人引入豐富的排名指標技術，包括：出現率、滿意值、相容值與相似值，來強化查詢結果的排名次序，以提供使用者更佳的呈現結果。經實驗顯示，本代理人的確能提升查詢解答的精確值，並呈現較佳的排名效果。
本系統的成果之四為發展搜尋代理人的使用者導向與領域聚焦兼顧之網路搜尋技術。引進本體論支援的網站模式提供搜尋引擎具語意層次的解答，藉以產出快速、精準、穩定與高滿意度的搜尋結果。由於網站模式與領域本體論的關聯密切，在網站模式的建構與應用上能支援包括：查詢擴展、網頁註解、網頁與網站分類、以及兼顧領域相關與使用者興趣的網路資源收集。本代理人的特色為(1)本體論支援的網站模式建構：提出將領域語意引進網路資源蒐集與儲存的觀念，重要的成果是一個能精準且穩定分類網頁，並支援正確語意註解之新的本體論分類器OntoClassifier，經實驗顯示，本分類器確能獲致滿意的網頁分類結果；(2)網站模式支援的網路資源探索：兼顧了使用者興趣與領域特殊性，成果之一為引進具使用者查詢驅動之網頁擴展、自主式網站擴展、以及深度開發查詢結果等革新策略，來有效擴展網站模式之新的Focused Crawler；(3)網站模式支援的網頁擷取：揭露出以本體論特徵值當作快速索引架構，來定位出符合使用者需求網頁的功效。


Development of FAQ-master as a New Intelligent Web Information System

This thesis describes the result of our research in developing FAQ-master as an intelligent Web information system. The system is developed to perform intelligent discovery, retrieval, filtering, proxy, ranking and presentation of Web information to provide high-quality FAQ solutions to meet user information request. By a high quality answer we mean an answer that is profound, up-to-date, and relevant to the user’s question. We summarized problems into: how to faithfully capture user intention, how to effectively discover and aggregate Web information, how to present the relevant result to the user, and how to provide efficient proxy mechanism to help speed up the turn around time. We propose the following techniques to tackle the above issues: ontology, user models, website models, and data aggregation and proxy mechanisms. Based upon the techniques, FAQ-master was developed to contain four agents, namely, Interface Agent, Proxy Agent, Answerer Agent, and Search Agent, which can effectively and efficiently improve the search result from the following three aspects of the Web search activity, namely, user intention, document processing, and website search.
The Interface Agent was developed to work as an assistant between the user and FAQ system for capturing true user’s intention. Based on user modeling, template-based and ontology-supported techniques, the agent can support natural language query, enhanced by the pattern-match and template-based technique; assistance and guidance for human-machine interaction; and better personalized information services. It also handles user feedback on the suitability of the proposed responses. The Proxy Agent was developed to work as a two-tier mediator between the Interface Agent and backend Answerer Agent. It employs an ontology-enhanced intelligent proxy mechanism to effectively alleviate the overloading problem usually associated with a backend server. The Answerer Agent was developed to help clean, retrieve, and transform FAQ information collected from a heterogeneous environment, such as the Web, and stores it in an ontological database. It works as a back end process to perform ontology-directed information aggregation, supported by the wrapper technique, from the webpages collected by the Search Agent. Finally, the Search Agent was developed to work as an both user-oriented and domain-related Web information retrieval with the help of ontology-supported website models. This approach provides a semantic level solution for the Search Agent so that it can provide domain-specific, focused Web information discovery toward a high degree of user satisfaction.
Our first contribution is on the techniques of user modeling and query processing involved in the development of Interface Agent, which features ontology-supported, template-based user modeling technique and query processing. Our preliminary experimentation demonstrates that user intention and focus of up to eighty percent of the user queries can be correctly understood by the system. In addition, from the experiments we verify the robustness of the linguistic pattern match technique by demonstrating its effectiveness in analyzing users’ query intention and focus.
The second contribution is on the techniques of query prediction in Proxy Agent. The agent features following interesting points. First, it performs fast user-oriented mining and prediction by discovering frequent queries and predicted queries from user query history. The improved sequential pattern mining algorithm is made more efficient by the techniques of perfect hashing and database decomposition. Second, it performs ontology-directed case-based reasoning. The semantics of PC ontology, in particular the VRelationships, are used in determining similar cases, performing case adaptation, and case retaining. Our experiments show that the agent can share up to 70% of the query loading from the backend process, which helps a lot on the overall query performance.
The third contribution is on the techniques of organizing and processing unstructured Web information in Answerer Agent. The agent employs ontology as the key technique, supported by the wrapper techniques to help clean, retrieve, and transform unstructured FAQ information collected from a heterogeneous environment, and stores it in an ontological database, which reflects the ontological structure. When it comes to the retrieval of FAQs, the agent trims irrelevant query keywords, employs either full keywords or partial keywords to retrieve FAQs, and removes conflicting FAQs before turning the final results to the user, all of which are supported by ontology. In addition, to producing a more effective presentation of the search results, the agent employs an enhanced ranking technique, which includes Appearance Probability, Satisfaction Value, Compatibility Value, and Statistic Similarity Value as four measures with proper weights to rank the FAQs. Our experiments show the Agent does improve the precision rate and produces better ranking results.
The final contribution is on the techniques of reflecting both user-oriented and domain-focused aspects in web search in Search Agent. The agent features an ontology-supported website modeling technique to provide a semantic level solution for a search engine so that it can provide fast, precise and stable search results with a high degree of user satisfaction. The website modeling technique closely connected to the domain ontology, which supports the following functions in both website model construction and application: query expansion, webpage annotation, webpage/website classification, and focused collection of domain-related and user-interested Web resources. The agent features the following interesting characteristics. 1) Ontology-supported construction of website models. By this, we attribute domain semantics into the Web resources collected and stored in the local database. One important contribution here is the new Ontology-supported OntoClassifier which can do very accurate and stable classification on webpages to support more correct annotation of domain semantics. Our experiments show that Ontoclassifier performs very well in obtaining accurate and stable webpages classification. 2) Website models-supported web resource discovery. By this, we take into account both user interests and domain specificity. The contribution here is the new Focused Crawler which employs progressive strategies to do user query-driven webpage expansion, autonomous website expansion, and query results exploitation to effectively expand the website models. 3) Website models-supported Webpage Retrieval. By this, we leverage the power of ontology features as a fast index structure to locate most-wanted webpages for the user.



96級

王榮英 (Jung-Ying Wang) D9115007

蛋白質溶劑可接觸面積之預測與分析

近年來類神經網路與支持向量機等機器學習理論，被大量的使用於各類生物資訊問題的預測上，雖然可得到較高的準確度，但其最大的問題在於上述理論並不夠通透，無法深入的探究為什麼會得此結果，並進行進一步的分析。如目標殘基與其相鄰殘基間彼此之合作與競爭關係對預測之影響等。故於此論文中我們提出建構樣式字典與多線性迴歸分析法兩個理論，藉助此兩個理論進行一系列的統計分析，將有助於我們能更深入的瞭解，蛋白質殘基間之交互作用對溶劑可接觸面積的影響。
另一方面由於溶劑可接觸面積之預測，至今可分為兩大分支，既傳統的兩類別(或數個類別)的預測及實際值的預測。於本論文中我們提出了一個全新的預測系統，我們將此系統命名為SVM-Cabins。本系統先利用由蛋白質演化資訊所得的位置加權矩陣為特徵值，接著以累進切割集的切割方式，利用某一門檻值來進行傳統的兩類別切割，而後再以支持向量機針對不同的切割集，作溶劑可接觸面積之兩類別的預測，最後我們再將所得的所有切割集的兩類別預測結果，映射成溶劑可接觸面積之實際值。上述系統當我們採用13個不同的累進切割集來做預測，針對Barton502資料集，可達到平均絕對誤差15.1%及相關係數0.66，此預測之準確度為至今最佳的結果。由於本系統先採用傳統的兩類別預測，再導入至實際值之預測，故本系統可同時達到對兩類(既傳統及實際值預測)之最佳化。本系統之理論亦可以利用於任何預測之值介於一數值範圍間的所有問題。


Prediction and Evolutionary Information Analysis of Proteins Solvent Accessibility

The prediction problem of most machine learning prediction methods (e.g. neural networks, support vector machine etc.) is that they are not transparent. We cannot see into the neural networks or support vector machine to determine why we get a particular prediction. This prevents them to give any insight into the cooperatives or competitions of solvent accessibility of residues and their neighbors, despite their being good accurate predictors. Therefore, in this dissertation we develop methods of look-up tables and multiple linear regression to do the real values prediction of solvent accessibility and provide some important insight into the nearest neighbor effect analysis and evolutionary information analysis. 
In addition, a number of methods for predicting levels of solvent accessibility or accessible surface area (ASA) of amino acid residues in proteins have been developed. These methods either predict regularly spaced states of relative solvent accessibility or an analogue real value indicating relative solvent accessibility. In this dissertation, we develop a novel method, named as SVM-Cabins. It first predicts discrete states of ASA of amino acids from their evolutionary profile and then maps the predicted states onto a real valued linear space by simple algebraic methods. The prediction of ASA into larger number of ASA states and then finding a corresponding scheme for real value prediction may be helpful in integrating the two approaches of ASA prediction. Resulting performance of such a rigorous approach using 13-state ASA prediction is better than any reported method of ASA prediction known so far. Since, the method starts with the prediction of discrete states of ASA and leads to real value predictions, performance of prediction in binary states and real values are simultaneously optimized. Also, SVM-Cabins method can be used as a prediction system to predict test data their numerical values, if training data their answers are distributed inside a numerical range.





97級


陳宗騰 (Tsung-Teng Chen) D8602003

自我調適式專家系統

人工智慧領域中非常有名的Turing Test給予本研究的第一個動機：一個專家系統不應該單單具備固定的解題知識；它也應該如同人類專家一樣，可以透過改採不同的觀點或解題策略來解題。本研究中我們試圖引進語意網表示的知識調整機制來增強專家系統的自我調適能力—專家系統因此能夠改用不同的觀點或解題策略來排除解題過程中遇到的困難。
 傳統專家系統使用內建的解題知識及使用者提供的事實來求解，但這個事先建構的解題知識往往只能在事先假設的環境下運作，當使用者無法提供預期的輸入資料時，傳統專家系統即可能無法找到任何有用的解答。本研究中，我們在專家系統的推演過程中導入「自我調適(self-adaptability)」的觀念，並且提出一個能有效處理未預期情況的專家系統架構，讓專家系統可以在推理過程隨時組織新的操作知識(operational knowledge)來適應新的環境。藉由這種自我調適的特性，專家系統甚至在輸入資料不完全的情況下，仍然可以找到一個有用的解答。
 我們所提出來的系統架構中，利用語意網路(semantic network)來表示領域知識(domain knowledge)。領域知識由三大部份所組成，分別為條件知識(condition knowledge)、結論知識(conclusion knowledge)、以及一組用來鏈接條件知識與結論知識的屬性關連(attribute relation)。我們定義了四種在領域知識上的調適(adaptation)操作，分別命名為條件知識調適(condition knowledge adaptation)、操作知識調適(operational knowledge adaptation)、結論知識調適(conclusion knowledge adaptation)、及表現方式調適(presentation adaptation)。本研究專注於探討前三種知識調適方式對專家系統調適能力的影響。另外，我們也提出了專家系統內建知識庫與外在語意詞庫合作的觀念，並藉由這種合作機制來擴展專家系統的調適能力，這樣也可藉由外在語意詞庫來減少知識工程師在建構專家系統知識庫時的工作量。
 為了實現前述的知識調適能力，我們定義出兩個最基本的知識調適操作，分別為一般化知識調適(generalization knowledge adaptation)及特殊化知識調適(specialization knowledge adaptation)。此外，我們同時也根據系統在推演過程中是否需要使用者的指引，提出了兩種不同的調適策略，分別為監督式調適策略(supervised adaptation policy)及非監督式調適策略(unsupervised adaptation policy)。非監督式調適策略模式適合對問題背景知識較不熟悉的使用者，在此模式下，專家系統僅完全依靠內建知識庫所包含的各種觀念及相互間的層次關係來自動地進行知識調適的操作。另一方面，對一個具有問題背景知識的進階使用者來說，他可以利用監督式調適策略，在推理過程中提供適當的資訊來指引知識調適操作的進行，以求能快速地找到一個正確的解答。我們分別為這兩種調適策略定義了兩種不同的知識調適操作，分別命名為監督式知識調適及非監督式知識調適。
 此外，為了讓自我調適式的專家系統能有效地找到一個好解答，我們提出了兩個以亂度(entropy)為基礎的量測：一個量測是用來在眾多可能的知識調適操作中，找出造成最小資訊損失(information loss)的操作；另一個量測則是讓系統在產生操作知識時，可以從眾多屬性關連(attribute relation)中找到最佳者。
我們還證明出，具有我們所提架構的自我調適式專家系統，不只在一般情況下可以找到一個正規的解答，在面臨未預期情況時，也可以藉由知識調適能力來自動地調適其操作知識並找到一個有意義的解答。最後，我們還透過一個精簡的例子來進一步說明自我調適式專家系統的運作方式。

Making Expert Systems Self-Adaptive

The famous Turing Test gives the first inspiration to this research: an expert system should not be hard-wired with problem-solving knowledge; it should be able to exhibit the problem-solving capability like a human expert. In this study, we try to improve the self-adaptability of an expert system by regulating semantic-network-represented knowledge so that it can exhibit human-like behavior by taking flexible viewpoints to solve problems.
 The pre-built knowledge of traditional expert systems is only capable of limited responses to changes in the operating environment. If the data input is unexpected, a traditional system may fail to reach any rational conclusions. In our study, we introduce the concept of self-adaptability to the inference process of an expert system, and propose an architecture that is capable of handling unexpected user input effectively and efficiently. Such a system can formulate operational knowledge on the move for inference. With this self-adaptive capability, an expert system can reach useful conclusions, even when the input data is insufficient. 
 The architecture of the proposed system encodes domain knowledge with semantic networks, which contain conclusion knowledge, condition knowledge, and attribute relations that relate the two types of knowledge together. We also define four types of adaptation, namely, condition knowledge adaptation, operational knowledge adaptation, conclusion knowledge adaptation, and presentation adaptation, and focus on how the first three contribute to the adaptive capability of the system. We also proposed the concept of the cooperation of the built-in domain knowledge and external semantic lexicon to extend the adaptability of the system and reduce the workload of a knowledge engineer in constructing domain knowledge. 
 We have defined two primary knowledge adaptation operations for realizing the adaptation mechanism in a self-adaptive expert system, which are generalization knowledge adaptation, and specialization knowledge adaptation. In addition, based on whether the assistance of the end-user advice is needed during the knowledge adaptation process, two adaptation policies are proposed, namely, supervised adaptation policy and unsupervised adaptation policy. The unsupervised adaptation policy mode is for an unskilled end-user, which allows the system to fully automatically perform knowledge adaptation based on the internal concept hierarchies of built-in domain knowledge. On the other hand, a proficient end-user can direct the process of knowledge adaptation under the supervised adaptation policy mode in order to find a useful conclusion quickly. We have also defined two corresponding types of knowledge adaptation operations for different adaptation policies, namely, unsupervised knowledge adaptation, and supervised knowledge adaptation.
 In addition, to enable a self-adaptive expert system to effectively produce better conclusions, two entropy-based measuring mechanisms are proposed: one minimizes the information loss during knowledge adaptation, while the other selects the best attribute relation during the generation of operational knowledge. 
 We have proved that a self-adaptive expert system based on this architecture can always reach a regular conclusion or an abstract conclusion, which is a more meaningful conclusion by automatically modifying its operational knowledge in response to user feedback during the inference process, even in unexpected situations. Finally, we have demonstrated a small but clear example to illustrate how a self-adaptive expert system works.




朱邦弘 (Bong-Horng Chu) D8902102

從真實資料挖掘可行動知識做客戶保留與障礙排除之客戶服務

客戶關係管理已成為現代企業卓越的商業策略之一，其中客戶保留和客戶服務被公認是最重要且具效益的商業活動。客戶關係管理目前可仰賴多樣的智慧型技術，本論文即針對客戶保留及障礙排除等客戶服務工作，提出新穎的方法來妥適整合各項智慧型技術，俾能自動淬取出有助於增裕營收之可行動知識。
在客戶保留工作方面，我們提出了一個「先分類再分群」的機制，針對可能流失客戶的特有屬性，自動找出可行動客戶保留策略來。我們先採用決策樹分類演算法來開發流失預測模型，再提出兩種不同方式來建構保留策略模型並加以應用。第一種方式使用改良過的階層式自動成長自我組織映射圖分群技術，先將流失客戶區分成為數個經明確標記的群集，再針對這些標記手動給定對應的具體保留策略。第二種方式則是運用關聯式規則探勘技術，從所有流失客戶的屬性值間找出關係，來建立出客戶流失關聯屬性值群集模型。我們特地建構了一個廣泛對應於客戶叛離的種種可能原因之客戶保留策略知識本體。藉由此知識本體之協助，即可利用客戶流失關聯屬性值群集模型來進一步建立出保留策略模型。此保留策略模型記錄了客戶群集與合適保留策略間的對應關係，因此可自動提供可行動保留策略給高值之潛在流失客戶。
在客戶服務方面，我們著重於針對真實客戶服務資料庫做知識探勘來自動建構障礙排除規則庫之方法。此障礙排除規則庫可針對客戶所提出的使用問題，提出可行動解答，除可減輕客服中心的人力負荷，復得提供客戶高品質的即時服務。為了能妥善處理真實資料庫，我們提出了一個「知識本體支援之資料修整技術」。利用文字探勘技術，我們從「備註資料欄」中擷取內含之有意義資訊，並據以修整資料庫。修整後之資料庫便可以用資料探勘模組來挖掘出更多隱含之障礙排除規則來，以提供更好之障礙排除解答給客戶。
我們以行動通信領域做為實際案例研究，並在一個真實客戶服務歷史資料庫上進行實驗。實驗證明，我們所提的方法論不僅有理論上的依據，也具備了實務上的效益。在客戶保留工作上，經由採用貪婪演算法來進行模型最佳化以及特徵選擇後，令我們驚異的，客戶社經相關屬性並非總是決定客戶是否叛離的重要因子。實驗結果也顯示，只具十個屬性的流失預測模型也能得到頗高的預測準確度。在障礙排除服務上，我們引進了限制式關聯式規則探勘技術，並且解決了在建構可行動障礙排除規則庫過程中，所遭遇的兩個主要問題，亦即，「稀有項目問題」以及「異常規則問題」。此外，在規則推論的過程中，我們均將規則本身的「信心度」明確地考慮進去，因此最後得到的結果是以一組依信心度大小而排列的可能解答。這個設計可以有效改善單一解答所可能造成的錯誤判斷。我們也很小心地在規則鏈結時利用信心度計算技巧來抑制傳遞誤差。我們的實驗亦證明了可以從修整後之資料庫，得到更多有意義的詞彙，並可進一步獲得更多有用的障礙排除規則，與直接從原始資料庫進行規則探勘相比，我們的方法確能得到更高的總體規則準確度。

Discovering Actionable Knowledge from Real-Life Data for Customer Retention and Troubleshooting Customer Service

Customer relationship management (CRM) has become one of the preeminent business strategies of modern business. Among the CRM efforts, customer retention and customer service are believed to be the most important and effective business activities. Nowadays, intelligent techniques are becoming more than necessary for CRM tasks. In this dissertation, we propose several novel ways for customer retention and customer service, by integrating proper intelligent techniques to help automatically extract the real nuggets of knowledge: actions useful for making profit.
In customer retention, we propose a classification-followed-by-clustering mechanism to automatically discover actionable customer retention policies for possible churners according to their specific characteristics. We use the decision tree-based algorithm to develop a churn predictive model. We then propose and compare two different approaches for constructing retention policy model and applying the models. The first approach handles the policy proposing issue by segmenting the churners into distinctly labeled clusters using modified GHSOM. With these labeled churner clusters, specific retention policies are manually associated. The second approach creates a churn attribute cluster model by exploiting the correlations among the attribute values of all churners using an association rules mining technique. With the support of retention policy ontology, which contains comprehensive retention policies corresponding to possible causes of customer defection, the churn attribute cluster model allows us to create a retention policy model that maps the clusters to appropriate retention policies. This mapping can then be used to automatically propose actionable retention policies for valuable churners.
In customer service, we focuses on automatically constructing a troubleshooting rule base by mining a real-life customer service database, and then uses the rule base to provide actionable solutions to the usage problems reported by the customers, so as to both relieve the manpower shortage of the call center and provide real-time quality service. In order to properly deal with a real-life database, we introduces an “ontology-supported refurbishing” technique by using text-mining techniques to retrieve significant information embedded in the remark fields to “refurbish” the database. The refurbished database can correctly attribute each service record with better physical meanings. The refurbished database then can be processed using a data mining module to discover implicit troubleshooting rules, which can be used to provide better troubleshooting solutions to customers. 
Taking the wireless telecommunication domain as a case study, our study demonstrates both the theoretical and practical strengths of the proposed methodology via experimenting on real-life historical customer services database. In customer retention, a very interesting finding that the demographic-related attributes may not always be crucial in deciding customer defection is revealed via introducing the greedy algorithm to do model optimization and feature selection. Experimental results showed that the churn predictive model, containing only ten attributes, can reach a high degree of prediction accuracy. In troubleshooting service, we utilize a constrained association rules mining method and have solved two significant problems during the construction of actionable troubleshooting rules, namely, the “rare item problem” and the “anomalous rule problem”. The “confidence” value of a mined rule is explicitly taken into consideration in the rule inference phase, therefore the results contain a list of possible processes ranked in the descending order of the confidence values. This design can effectively alleviate potential wrong judgment with only one result. We also carefully introduce a confidence calculation mechanism for rule chaining to suppress propagating errors. From the refurbished database, our experiments demonstrated that more significant terms and more useful troubleshooting rules can be derived and the total accuracy of the set of mined rules is significantly increased than that from the original database.